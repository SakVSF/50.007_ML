# -*- coding: utf-8 -*-
"""
Created on Mon Apr  3 00:50:27 2023

@author: User
"""
from utilities import * 
import math
import numpy as np
import random
from collections import Counter
from part1 import *


# Enable floating-point underflow warnings and disable divide-by-zero warnings
np.seterr(under="warn", divide="ignore")


def estimate_transition_parameters(training_set, N):
    
    # Calculating the estimated transition probabilities
    transition_probs = np.zeros((N+2, N+2),  dtype=np.longdouble)
    transition_counts = np.zeros((N+2, N+2),  dtype=np.longdouble)
    label_counts = [0]*(N+2)

    #print(training_set[len(training_set)][1])
    count=0
    for i in range(1, len(training_set)):
        prev_tag = training_set[i-1][1]
        curr_tag = training_set[i][1]
        transition_counts[prev_tag][curr_tag] += 1
        label_counts[prev_tag] += 1

    label_counts[-1]=+1 #for STOP tag
    #print(transition_counts[1][19])
    for i in range(len(label_counts)):
        transition_probs[i][:] = transition_counts[i][:]/label_counts[i]
        #print("For",i,transition_probs[i][:])
    
    #print("Label counts", label_counts)
    print("Transition table",transition_probs)
    return transition_probs  #20*20 array (20 rows and 20 columns. No of tags =19, 2 extra tags are START AND STOP)

  

def viterbi(sentence, tags, trans_prob, emission_prob, all_tokens):
    """
    Runs the Viterbi algorithm on a sentence with the given model parameters.

    Arguments: sentence (list): A list of words in the sentence.
               tags (list): A list of possible tags.
               trans_prob (dict): A dictionary containing the transition probabilities between each pair of tags.
               emission_prob (dict): A dictionary containing the emission probabilities of each word for each tag.
    Returns list: A list of the most likely tags for the words in the sentence.

    """
    # Initializing the trellis
    
    


    trellis = [{0:{"prob":0, "prev":None},
    1: {"prob":0, "prev":None}, 
    2:{"prob":0, "prev":None},
    3:{"prob":0, "prev":None},
    4:{"prob":0, "prev":None},
    5:{"prob":0, "prev":None},
    6:{"prob":0, "prev":None},
    7:{"prob":0, "prev":None},
    8:{"prob":0, "prev":None},
    9:{"prob":0, "prev":None},
    10:{"prob":0, "prev":None},
    11:{"prob":0, "prev":None},
    12:{"prob":0, "prev":None},
    13:{"prob":0, "prev":None},
    14:{"prob":0, "prev":None},
    15:{"prob":0, "prev":None},
    16:{"prob":0, "prev":None},
    17:{"prob":0, "prev":None},
    18:{"prob":0, "prev":None},
    19:{"prob":0, "prev":None}} 
    for i in range(len(sentence)+2)]
    tags = ["START","O", "B-ADJP", "I-ADJP","B-ADVP","I-ADVP","B-CONJP","I-CONJP","B-INTJ","I-INTJ","B-NP","I-NP", "B-PP","I-PP","B-PRT", "B-SBAR","I-SBAR","B-VP","I-VP", "STOP"]
   
    count =0
    emission_label= {
          "O": 0,
          "B-ADJP":1,
          "I-ADJP":2,
          "B-ADVP":3,
          "I-ADVP":4,
          "B-CONJP":5,
          "I-CONJP":6,
          "B-INTJ": 7,
          "I-INTJ": 8,
          "B-NP": 9,
          "I-NP": 10,
          "B-PP": 11,
          "I-PP": 12,
          "B-PRT":13,
          "B-SBAR":14,
          "I-SBAR":15,
          "B-VP": 16,
          "I-VP":17,
    }
 

   
    n_tags = len(tags)

    #initializing trellis
    for i in range(n_tags):
        if tags[i]=="START":
            trellis[0][i]["prob"] = 1
        else:
            trellis[0][i]["prob"] = 0

    # Filling in the rest of the trellis
    for i in range(1, len(sentence)+1):
        
        for tag in tags:
            max_prob = 0
            max_prev = None
            u = labels_EN[tag]
          
            for prev_tag in tags:

                v = labels_EN[prev_tag]
                trans_p = trans_prob[v][u]
                prev_prob = trellis[i-1][v]["prob"]

                if tag=="START" or tag=="STOP":
                        prob = prev_prob * \
                            trans_p* \
                            0 
                else:

                    if sentence[i-1] in all_tokens:
                        emission_p = emission_prob[emission_label[tag]][all_tokens.index(sentence[i-1])]
                        prob = prev_prob*  \
                        trans_p* \
                        emission_p       
    

                    else:
                        emission_p = emission_prob[emission_label[tag]][-1] #UNK token
                        prob = prev_prob* \
                                trans_p* \
                                emission_p
                            
                        
                   
                #print("Probability:", prob)
                if prob > max_prob:
                    max_prob = prob
                    max_prev = prev_tag


               
            if max_prob != 0:
                trellis[i][u] = {"prob": max_prob, "prev": max_prev}



    #Final Step (n+1)
    n= len(sentence)
    max_prob = 0
    max_prev = None
    for tag in tags:
        prev_prob = trellis[n][labels_EN[tag]]["prob"]
        transmission_prob = trans_prob[labels_EN[tag]][labels_EN['STOP']]
        
        prob = prev_prob*transmission_prob
        if prob > max_prob:
            max_prob = prob
            max_prev = tag
    '''
    if max_prob != 0:
        trellis[n+1][labels_EN['STOP']] = {"prob": max_prob, "prev": max_prev}
    print("MAX prev ending", max_prev)


    current_layer = n
    path_reverse = ["stop"]
    while current_layer >= 0:
        path_reverse.append(trellis[current_layer + 1][path_reverse[len(path_reverse) - 1]]['prev'])
        current_layer -= 1

    max_seq =  path_reverse[::-1][1:len(path_reverse) - 1]
    print("SEQUENCE",max_seq)
    return max_seq
'''

    # Finding the most likely tag sequence by backtracking through the trellis
    max_tag_seq = ['' for i in range(n)]

    if max_prev is None:
        max_prev = "O"

    for i in range(n+1, -1, -1):
        max_prev = trellis[i][labels_EN[max_prev]]["prev"]
        if max_prev== None:
            max_prev = "O"

        max_tag_seq[i-2] = max_prev
        
   # print("Max seq",max_tag_seq)
    return max_tag_seq






#reading and preprocessing of training data 
def read_train_data(path, labels):
    results = []
    results.append(('', labels["START"])) #append "START" tag to starting of file.

    with open(path, "r", encoding="utf-8") as file:
        for line in file:
            line = line.strip()
            if not line:             #get rid of empty lines and whitespaces
                continue
            token, label = line.rsplit(" ", 1)
            if label in labels_EN:
                results.append((token, labels[label]))

    results.append(('', labels["STOP"]))  #append STOP tag to ending of file. 

    return results


def read_test_data(path):
    sentence_list = [[]]
    with open(path, "r", encoding="utf-8") as file:
        
        for line in file:
            if line == "\n":
                sentence_list.append([])
            else:
                sentence_list[-1].append(line.rstrip())

    return sentence_list[:-1] #list where every element is itself a list of words of a sentence. Format : [[w1,w2,...end of sentence1], [w1,w2,...end of sentence2]...[last sentence]]




def viterbi_loop(test_data, transition_parameters, emission_parameters,labels, all_tokens):
    final = []
    for sentence in test_data:
        #print("Sentence", sentence)
        tags = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,7,18,19]
    
        final.append(viterbi(sentence, tags, transition_parameters, emission_parameters, all_tokens))
    return final


def write_viterbi_output_to_file(language):
    if language == "EN":
        
        #Emission parameters
        train_data_emission = read_training_data(en_train_path, labels_EN)
        all_tokens = get_tokens(train_data_emission)
        emission_parameters = estimate_emission_parameters(train_data_emission, all_tokens, N_EN)

        #transition parameters
        train_data_transition= read_train_data(en_train_path, labels_EN)
        #print("First 10 token-label pairs:",train_data[:10])
        transition_parameters = estimate_transition_parameters(train_data_transition, N_EN)

        #Viterbi call
        test_data = read_test_data(en_dev_in_path)
        tags = ["START","O", "B-ADJP", "I-ADJP","B-ADVP","I-ADVP","B-CONJP","I-CONJP","B-INTJ","I-INTJ","B-NP","I-NP", "B-PP","I-PP","B-PRT", "B-SBAR","I-SBAR","B-VP","I-VP", "STOP"]
   
        prediction = viterbi_loop(test_data, transition_parameters, emission_parameters, tags, all_tokens )

        with open(en_dev_p2_out_path, "w+", encoding="utf-8") as file:
            for i in range(len(test_data)):
                for j in range(len(test_data[i])):
                    if test_data[i][j] and prediction[i][j]:
                        file.write("{} {}\n".format(test_data[i][j], prediction[i][j]))
                    else:
                        file.write("\n")

'''
        states_viterbi = [[]]
        index = 0
        for observed_sequence in test_data:
            for state in viterbi(observed_sequence, transition_parameters, emission_parameters, tags, all_tokens ):
                states_viterbi[index].append(state)
            states_viterbi.append([])
            index += 1
        states_viterbi.pop()

  '''    
        #print(prediction)
       # print(prediction)
'''
        msg = ""
        for i in range(len(states_viterbi)):
            for j in range(len(states_viterbi[i])):
                msg += test_data[i][j]
                msg += ' '
                msg += states_viterbi[i][j]
                msg += '\n'
            msg += '\n'

        result = open("EN/dev.p2_edit.out", "wb")
        result.write(msg.encode("utf-8"))
        result.close()
        print("saved!")

        '''
        

write_viterbi_output_to_file("EN")